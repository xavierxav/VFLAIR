import os
import torch
import numpy as np
from tqdm import tqdm
from transformers import AutoModel
import tifffile as tiff

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Function to save class tokens
def save_class_tokens(batch_file_paths, class_tokens, output_dir, input_dir):
    for file_path, class_token in zip(batch_file_paths, class_tokens):
        relative_path = os.path.relpath(os.path.dirname(file_path), input_dir)
        output_path = os.path.join(output_dir, relative_path)
        os.makedirs(output_path, exist_ok=True)
        class_token_file_path = os.path.join(output_path, os.path.basename(file_path).replace('.tiff', '_class_token.npy'))
        np.save(class_token_file_path, class_token)

# Define a function to extract the class token from a batch of images
def extract_class_token_batch(image_paths, model , channels_list):
    all_class_tokens = []

    # Transform function to split images into four sub-images with 3 channels each
    def split_into_channels(image, channels_list):
        return [torch.tensor(image.reshape(12, 168, 168)[channels]) for channels in channels_list]
    # [
    #         torch.tensor(image.reshape(12, 168, 168)[:3]),    # First 3 channels
    #         torch.tensor(image.reshape(12, 168, 168)[3:6]),  # Next 3 channels
    #         torch.tensor(image.reshape(12, 168, 168)[6:9]),  # Next 3 channels
    #         torch.tensor(image.reshape(12, 168, 168)[9:12])  # Last 3 channels
    #     ]

    for image_path in image_paths:
        image = tiff.imread(image_path)
        split_images = split_into_channels(image , channels_list)
        split_images = [img.unsqueeze(0).to(device) for img in split_images]  # Add batch dimension and move to device
        with torch.no_grad():
            features = [model(img) for img in split_images]
        class_tokens = [feat[1].squeeze().cpu().numpy() for feat in features]  # Assuming the class token is the first token
        all_class_tokens.append(np.stack(class_tokens))  # Stack tokens for the 4 splits
    return all_class_tokens

def extract_class_tokens(input_dir = r'C:\Users\XD278777\Desktop\worldstrat\dataset\lr_dataset', output_dir = r'C:\Users\XD278777\Desktop\worldstrat\dataset\extracted_features', batch_size = 512, channels_list = [[2,3,4]]):

    # Create the output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Load DINOv2 model
    model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)
    model.eval()

    # Collect all files
    files_to_process = []
    for root, _, files in os.walk(input_dir):
        for file in files:
            if file.endswith('.tiff'):
                files_to_process.append(os.path.join(root, file))

    # Process files in batches with progress bar
    for i in tqdm(range(0, len(files_to_process), batch_size), desc="Processing images"):
        batch_file_paths = files_to_process[i:i+batch_size]
        class_tokens = extract_class_token_batch(batch_file_paths, model , channels_list)
        save_class_tokens(batch_file_paths, class_tokens, output_dir, input_dir)

    print("Class token extraction completed.")

if __name__ == '__main__':
    channels_list = [[2,3,4]]
    output_dir = r'C:\Users\XD278777\Desktop\worldstrat\dataset\extracted_features_rgb'
    extract_class_tokens(channels_list = channels_list, output_dir = output_dir)
